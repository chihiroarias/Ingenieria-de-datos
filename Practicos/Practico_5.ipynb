{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3a7f16",
   "metadata": {},
   "source": [
    "## üîç Parte 1: Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todas las librer√≠as importadas correctamente\n",
      "üé® Configuraci√≥n de visualizaciones lista!\n"
     ]
    }
   ],
   "source": [
    "# === SETUP DEL ENTORNO ===\n",
    "\n",
    "# 1. Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Todas las librer√≠as importadas correctamente\")\n",
    "\n",
    "# 3. Configurar visualizaciones\n",
    "plt.style.use('_______')  # estilo visual (ej: 'seaborn-v0_8', 'default', 'classic')\n",
    "sns.set_palette(\"_______\")  # paleta de colores (ej: 'husl', 'Set1', 'viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"üé® Configuraci√≥n de visualizaciones lista!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce6856",
   "metadata": {},
   "source": [
    "## üè† Paso 2: Cargar y Crear Missing Data Sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† DATASET: Ames Housing\n",
      "   üìä Forma original: (2930, 82)\n",
      "   üìã Columnas: ['Order', 'PID', 'MS SubClass', 'MS Zoning', 'Lot Frontage', 'Lot Area', 'Street', 'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Mas Vnr Area', 'Exter Qual', 'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin SF 1', 'BsmtFin Type 2', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air', 'Electrical', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual', 'TotRms AbvGrd', 'Functional', 'Fireplaces', 'Fireplace Qu', 'Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Cars', 'Garage Area', 'Garage Qual', 'Garage Cond', 'Paved Drive', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Pool QC', 'Fence', 'Misc Feature', 'Misc Val', 'Mo Sold', 'Yr Sold', 'Sale Type', 'Sale Condition', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# === CARGAR DATASET AMES HOUSING ===\n",
    "\n",
    "# 1. Cargar dataset base\n",
    "df = pd.read_csv('../datasets/AmesHousing.csv')\n",
    "\n",
    "print(\"üè† DATASET: Ames Housing\")\n",
    "print(f\"   üìä Forma original: {df.shape}\")\n",
    "print(f\"   üìã Columnas: {list(df.columns)}\")\n",
    "\n",
    "# 2. Crear missing data sint√©tico para pr√°ctica\n",
    "np.random.seed(42)  # para reproducibilidad\n",
    "\n",
    "# Simular MCAR en Year Built (8% missing aleatorio)\n",
    "# \"Los valores faltan al azar: que falte un Year Built no depende de la edad ni del propio Year Built\"\n",
    "missing_year = np.random.random(len(df)) < 0.08\n",
    "df.loc[missing_year, 'Year Built'] = np._____\n",
    "\n",
    "# Simular MAR en Garage Area (missing relacionado con Garage Type)\n",
    "# \"Los faltantes de Garage Area se concentran en ciertos tipos de garaje (variable observada)\"\n",
    "df.loc[df['Garage Type'] == 'None', 'Garage Area'] = df.loc[df['Garage Type'] == 'None', 'Garage Area'].sample(frac=0.7, random_state=42)\n",
    "\n",
    "# Simular MNAR en SalePrice (missing relacionado con precio alto)\n",
    "# \"Los faltantes dependen del propio valor: quienes tienen precios altos no reportan precio\"\n",
    "high_price = df['SalePrice'] > df['SalePrice'].quantile(0.85)\n",
    "df.loc[high_price, 'SalePrice'] = df.loc[high_price, 'SalePrice'].sample(frac=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nüîç Missing data sint√©tico creado:\")\n",
    "print(df._____().sum())  # m√©todo para contar valores faltantes por columna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dc778",
   "metadata": {},
   "source": [
    "## üìä Paso 3: An√°lisis Inicial del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55feb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPLORACI√ìN B√ÅSICA ===\n",
    "\n",
    "# 1. Informaci√≥n general del dataset\n",
    "print(\"=== INFORMACI√ìN GENERAL ===\")\n",
    "print(df._____())  # m√©todo que muestra tipos de datos, memoria y valores no nulos\n",
    "\n",
    "# 2. Estad√≠sticas descriptivas\n",
    "print(\"\\n=== ESTAD√çSTICAS DESCRIPTIVAS ===\")\n",
    "print(df._____())  # m√©todo que calcula estad√≠sticas descriptivas\n",
    "\n",
    "# 3. Tipos de datos\n",
    "print(\"\\n=== TIPOS DE DATOS ===\")\n",
    "print(df._____)  # atributo que muestra tipos de datos por columna\n",
    "\n",
    "# 4. Verificar missing data\n",
    "print(\"\\n=== MISSING DATA POR COLUMNA ===\")\n",
    "missing_count = df._____().sum()  # contar valores faltantes\n",
    "missing_pct = (missing_count / len(df)) * 100  # calcular porcentaje\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': missing_count,\n",
    "    'Missing_Percentage': missing_pct\n",
    "})\n",
    "print(missing_stats[missing_stats['Missing_Count'] > 0])\n",
    "\n",
    "# 5. An√°lisis de memoria\n",
    "print(\"\\n=== AN√ÅLISIS DE MEMORIA ===\")\n",
    "total_bytes = df._____(deep=True).sum()  # m√©todo para memoria en bytes\n",
    "print(f\"Memoria total del DataFrame: {total_bytes / (1024**2):.2f} MB\")\n",
    "print(f\"Memoria por columna:\")\n",
    "for col in df.columns:\n",
    "    memory_usage = df[col]._____()  # m√©todo para memoria de una columna\n",
    "    print(f\"  {col}: {memory_usage / 1024:.2f} KB\")\n",
    "\n",
    "# 6. An√°lisis de duplicados\n",
    "print(\"\\n=== AN√ÅLISIS DE DUPLICADOS ===\")\n",
    "duplicates = df._____()  # m√©todo para detectar filas duplicadas\n",
    "print(f\"N√∫mero de filas duplicadas: {duplicates.sum()}\")\n",
    "if duplicates.sum() > 0:\n",
    "    print(\"Primeras 5 filas duplicadas:\")\n",
    "    print(df[df._____()].head())  # m√©todo para filtrar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56276851",
   "metadata": {},
   "source": [
    "## üîç Paso 4: Detecci√≥n de Patrones de Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3140f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS DE PATRONES DE MISSING DATA ===\n",
    "\n",
    "# 1. Filtrar solo columnas con missing data para visualizaci√≥n\n",
    "missing_columns = df.columns[df._____().any()].tolist()  # m√©todo para detectar missing\n",
    "print(f\"Columnas con missing data: {len(missing_columns)}\")\n",
    "print(f\"Columnas: {missing_columns}\")\n",
    "\n",
    "# 2. Visualizaci√≥n mejorada sin missingno\n",
    "plt.subplot(1, 1, 1)\n",
    "if len(missing_columns) > 0:\n",
    "    # Crear estad√≠sticas de missing solo para columnas con missing data\n",
    "    missing_count = df[missing_columns]._____().sum()  # m√©todo para contar missing\n",
    "    missing_pct = (missing_count / len(df)) * 100  # calcular porcentaje\n",
    "\n",
    "    missing_stats_filtered = pd.DataFrame({\n",
    "        'Column': missing_columns,\n",
    "        'Missing_Count': missing_count,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    }).sort_values('Missing_Percentage', ascending=False).head(10)\n",
    "\n",
    "    # Crear gr√°fico de barras m√°s limpio\n",
    "    bars = plt._____(range(len(missing_stats_filtered)), missing_stats_filtered['Missing_Percentage'], \n",
    "                   color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.5)  # funci√≥n para barras\n",
    "    plt.title('Top 10: Porcentaje de Missing por Columna', fontsize=14, fontweight='bold')\n",
    "    plt._____(range(len(missing_stats_filtered)), missing_stats_filtered['Column'], \n",
    "               rotation=45, ha='right')  # funci√≥n para etiquetas del eje X\n",
    "\n",
    "    plt.ylabel('Porcentaje de Missing (%)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Agregar valores en las barras\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No hay missing data', ha='center', va='center', fontsize=16)\n",
    "    plt.title('Porcentaje de Missing por Columna', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Distribuci√≥n de missing por fila\n",
    "plt.show()\n",
    "plt.subplot(1, 1, 1)\n",
    "missing_per_row = df._____().sum(axis=1)  # contar missing por fila\n",
    "plt._____(missing_per_row, bins=range(0, missing_per_row.max()+2), alpha=0.7, \n",
    "         edgecolor='black', color='lightcoral')  # funci√≥n para histograma\n",
    "plt.title('Distribuci√≥n de Missing por Fila', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('N√∫mero de valores faltantes por fila')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "!mkdir -p results/visualizaciones\n",
    "plt.savefig('results/visualizaciones/missing_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4135391",
   "metadata": {},
   "source": [
    "## üß† Paso 5: Clasificar Tipos de Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca32295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLASIFICACI√ìN MCAR/MAR/MNAR ===\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE TIPOS DE MISSING ===\")\n",
    "\n",
    "# 1. Year Built: ¬øMCAR o MAR?\n",
    "print(\"\\n1. YEAR BUILT - An√°lisis de patrones:\")\n",
    "year_missing = df['Year Built']._____()  # m√©todo para detectar missing\n",
    "print(\"Missing Year Built por Neighborhood:\")\n",
    "print(df.groupby('Neighborhood')['Year Built'].apply(lambda x: x._____().sum()))  # contar missing por grupo\n",
    "\n",
    "print(\"Missing Year Built por House Style:\")\n",
    "print(df.groupby('House Style')['Year Built'].apply(lambda x: x._____().sum()))\n",
    "\n",
    "# 2. Garage Area: ¬øMAR?\n",
    "print(\"\\n2. GARAGE AREA - An√°lisis de patrones:\")\n",
    "print(\"Missing Garage Area por Garage Type:\")\n",
    "print(df.groupby('Garage Type')['Garage Area'].apply(lambda x: x._____().sum()))\n",
    "\n",
    "# 3. SalePrice: ¬øMNAR?\n",
    "print(\"\\n3. SALEPRICE - An√°lisis de patrones:\")\n",
    "price_missing = df['SalePrice']._____()\n",
    "print(\"Valores de SalePrice en registros con missing:\")\n",
    "print(df[price_missing]['SalePrice']._____())  # estad√≠sticas descriptivas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d6c12",
   "metadata": {},
   "source": [
    "## üö® Paso 6: Detecci√≥n de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33393285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DETECCI√ìN DE OUTLIERS CON IQR ===\n",
    "# \"Detectar extremos usando mediana y cuartiles\"\n",
    "# \"Cu√°ndo usar: distribuciones asim√©tricas / colas pesadas / presencia de outliers\"\n",
    "if \"Year Built\" in df.columns:\n",
    "    df[\"Year Built\"] = pd.to_numeric(df[\"Year Built\"], errors=\"coerce\")\n",
    "\n",
    "# === DETECCI√ìN DE OUTLIERS: IQR y Z-SCORE (robustas) ===\n",
    "def detect_outliers_iqr(df, column, factor=1.5):\n",
    "    \"\"\"Outliers por IQR. Devuelve (df_outliers, lower, upper).\"\"\"\n",
    "    x = pd.to_numeric(df[column], errors=\"coerce\")\n",
    "    x_no_na = x.dropna().astype(float).values\n",
    "    if x_no_na.size == 0:\n",
    "        # sin datos v√°lidos\n",
    "        return df.iloc[[]], np.nan, np.nan\n",
    "    q1 = np.percentile(x_no_na, 25)\n",
    "    q3 = np.percentile(x_no_na, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - factor * iqr\n",
    "    upper = q3 + factor * iqr\n",
    "    mask = (pd.to_numeric(df[column], errors=\"coerce\") < lower) | (pd.to_numeric(df[column], errors=\"coerce\") > upper)\n",
    "    return df[mask], lower, upper\n",
    "\n",
    "# Analizar outliers en columnas num√©ricas\n",
    "numeric_columns = df._____(include=[np.number]).columns  # m√©todo para seleccionar columnas num√©ricas\n",
    "outlier_analysis = {}\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if not df[col]._____().all():  # m√©todo para verificar si hay missing data\n",
    "        outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "        outlier_analysis[col] = {\n",
    "            'count': len(outliers),\n",
    "            'percentage': (len(outliers) / len(df)) * 100,\n",
    "            'lower_bound': lower,\n",
    "            'upper_bound': upper\n",
    "        }\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_analysis).T\n",
    "print(\"=== AN√ÅLISIS DE OUTLIERS (IQR) ===\")\n",
    "print(\"√ötil cuando la distribuci√≥n est√° chueca o con colas largas\")\n",
    "print(outlier_df)\n",
    "\n",
    "# An√°lisis adicional de outliers\n",
    "print(\"\\n=== RESUMEN DE OUTLIERS ===\")\n",
    "total_outliers = outlier_df['count']._____()  # m√©todo para sumar outliers\n",
    "print(f\"Total de outliers detectados: {total_outliers}\")\n",
    "print(f\"Porcentaje promedio de outliers: {outlier_df['percentage']._____():.2f}%\")  # m√©todo para calcular media\n",
    "print(f\"Columna con m√°s outliers: {outlier_df['count']._____()}\")  # m√©todo para encontrar m√°ximo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91dfb23",
   "metadata": {},
   "source": [
    "## üîç Paso 7: Detecci√≥n de Outliers con Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DETECCI√ìN DE OUTLIERS CON Z-SCORE ===\n",
    "# \"Cu√°ndo usar: distribuci√≥n aprox. campana y sin colas raras\"\n",
    "# \"Regla: 3 pasos (desvios) desde el promedio = raro\"\n",
    "\n",
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    \"\"\"Detectar outliers usando Z-Score - Regla: 3 desvios desde el promedio = raro\"\"\"\n",
    "    from scipy import stats\n",
    "    z_scores = np.abs(stats.zscore(df[column].dropna()))\n",
    "    outlier_indices = df[column].dropna().index[z_scores > threshold]\n",
    "    return df.loc[outlier_indices]\n",
    "\n",
    "# Comparar m√©todos de detecci√≥n\n",
    "print(\"\\n=== COMPARACI√ìN DE M√âTODOS DE DETECCI√ìN ===\")\n",
    "for col in ['SalePrice', 'Lot Area', 'Year Built', 'Garage Area']:\n",
    "    if col in df.columns and not df[col].isnull().all():\n",
    "        iqr_outliers = detect_outliers_iqr(df, col)\n",
    "        zscore_outliers = detect_outliers_zscore(df, col)\n",
    "\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  IQR outliers: {len(iqr_outliers[0])} ({len(iqr_outliers[0])/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Z-Score outliers: {len(zscore_outliers)} ({len(zscore_outliers)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903562c",
   "metadata": {},
   "source": [
    "## üìä Paso 8: Visualizaci√≥n de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZAR OUTLIERS ===\n",
    "\n",
    "# Crear directorio para resultados\n",
    "import os\n",
    "os._____('results/visualizaciones', exist_ok=True)  # m√©todo para crear directorio\n",
    "\n",
    "# Visualizar outliers con boxplots\n",
    "fig, axes = plt._____(2, 2, figsize=(15, 12))  # funci√≥n para crear subplots\n",
    "axes = axes._____()  # m√©todo para aplanar array\n",
    "\n",
    "for i, col in enumerate(['SalePrice', 'Lot Area', 'Year Built', 'Garage Area']):\n",
    "    if col in df.columns and not df[col]._____().all():  # m√©todo para verificar missing\n",
    "        # Boxplot\n",
    "        sns._____(data=df, y=col, ax=axes[i])  # funci√≥n para boxplot\n",
    "        axes[i].set_title(f'Outliers en {col}', fontweight='bold')\n",
    "        axes[i].set_ylabel(col)\n",
    "\n",
    "        # Marcar outliers\n",
    "        outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "        if len(outliers) > 0:\n",
    "            axes[i]._____([0] * len(outliers), outliers[col], \n",
    "                           color='red', alpha=0.6, s=50, label=f'Outliers ({len(outliers)})')  # funci√≥n para scatter\n",
    "            axes[i]._____()  # m√©todo para mostrar leyenda\n",
    "\n",
    "plt._____()  # funci√≥n para ajustar layout\n",
    "plt._____('results/visualizaciones/outliers_analysis.png', dpi=300, bbox_inches='tight')  # funci√≥n para guardar\n",
    "plt._____()  # funci√≥n para mostrar gr√°fico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e73bb",
   "metadata": {},
   "source": [
    "## üîß Paso 9: Estrategias de Imputaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPLEMENTAR ESTRATEGIAS DE IMPUTACI√ìN ===\n",
    "# \"Rellenar no es gratis; hacelo columna a columna y document√°\"\n",
    "# \"Num: mediana (si cola pesada) / media (si ~normal)\"\n",
    "# \"Cat: moda o 'Unknown' (+ flag si sospecha MNAR)\"\n",
    "\n",
    "def impute_missing_data(df, strategy='median'):\n",
    "    \"\"\"Implementar diferentes estrategias de imputaci√≥n - Reglas simples de la clase\"\"\"\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                if strategy == 'mean':\n",
    "                    df_imputed[col].fillna(df[col]._____(), inplace=True)  # imputar con media\n",
    "                elif strategy == 'median':\n",
    "                    df_imputed[col].fillna(df[col]._____(), inplace=True)  # imputar con mediana\n",
    "                elif strategy == 'mode':\n",
    "                    df_imputed[col].fillna(df[col]._____()[0], inplace=True)  # imputar con moda\n",
    "            else:\n",
    "                # Para variables categ√≥ricas\n",
    "                df_imputed[col].fillna(df[col]._____()[0], inplace=True)  # imputar con moda\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# Probar diferentes estrategias\n",
    "strategies = ['mean', 'median', 'mode']\n",
    "imputed_datasets = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    imputed_datasets[strategy] = impute_missing_data(df, strategy)\n",
    "    print(f\"Estrategia {strategy}: {imputed_datasets[strategy].isnull().sum().sum()} missing values restantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2b679",
   "metadata": {},
   "source": [
    "## üß† Paso 10: Imputaci√≥n Inteligente por Tipo de Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPUTACI√ìN INTELIGENTE ===\n",
    "\n",
    "def smart_imputation(df):\n",
    "    \"\"\"Imputaci√≥n inteligente basada en el tipo de missing data\"\"\"\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    # Year Built: MAR - imputar por Neighborhood y House Style\n",
    "    year_by_group = df.groupby(['Neighborhood', 'House Style'])['Year Built']._____()  # mediana por grupo\n",
    "    for (neighborhood, style), median_year in year_by_group.items():\n",
    "        mask = (df['Neighborhood'] == neighborhood) & (df['House Style'] == style) & df['Year Built']._____()  # condici√≥n para missing\n",
    "        df_imputed.loc[mask, 'Year Built'] = median_year\n",
    "\n",
    "    # Garage Area: Crear categor√≠a \"Unknown\" para MNAR\n",
    "    df_imputed['Garage Area'].fillna('_____', inplace=True)  # valor para missing\n",
    "\n",
    "    # SalePrice: Imputar con mediana por Neighborhood\n",
    "    price_by_neighborhood = df.groupby('Neighborhood')['SalePrice']._____()  # mediana por Neighborhood\n",
    "    for neighborhood, median_price in price_by_neighborhood.items():\n",
    "        mask = (df['Neighborhood'] == neighborhood) & df['SalePrice']._____()  # condici√≥n para missing\n",
    "        df_imputed.loc[mask, 'SalePrice'] = median_price\n",
    "\n",
    "    # Garage Type: Imputar con moda (MCAR)\n",
    "    df_imputed['Garage Type'].fillna(df['Garage Type']._____()[0], inplace=True)  # moda\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# Aplicar imputaci√≥n inteligente\n",
    "df_smart_imputed = smart_imputation(df)\n",
    "print(\"=== IMPUTACI√ìN INTELIGENTE ===\")\n",
    "print(f\"Missing values restantes: {df_smart_imputed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622b171",
   "metadata": {},
   "source": [
    "## üö´ Paso 11: Anti-Leakage B√°sico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
